{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "import pandas as pd\n",
    "from random import random\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "%matplotlib inline\n",
    "\n",
    "class dummy(ml.classifier):\n",
    "    def __init__(self,X,Y,P): self.P=P; self.classes=np.unique(Y);\n",
    "    def predictSoft(self,X): return self.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7423, 45)\n",
      "(7422, 45)\n"
     ]
    }
   ],
   "source": [
    "X = np.genfromtxt('X_train.txt', delimiter=',')\n",
    "Y = np.genfromtxt('Y_train.txt', delimiter=',')\n",
    "Xte = np.genfromtxt('X_test.txt', delimiter=',')\n",
    "\n",
    "X = X[:,[28,56,7,22,58,24,52,42,5,30,14,47,51,6,1,16,27,94,20,68,\n",
    "        69,72,85,100,15,0,73,75,76,78,79,83,84,86,87,90,92,96,97,102,33,37,60,61,35]]\n",
    "Xte = Xte[:,[28,56,7,22,58,24,52,42,5,30,14,47,51,6,1,16,27,94,20,68,\n",
    "        69,72,85,100,15,0,73,75,76,78,79,83,84,86,87,90,92,96,97,102,33,37,60,61,35]]\n",
    "\n",
    "print(X.shape)\n",
    "print(Xte.shape)\n",
    "\n",
    "[Xtr, Xva, Ytr, Yva] = ml.splitData(X,Y,0.8)\n",
    "\n",
    "Xtr, param = ml.transforms.rescale(Xtr)\n",
    "Xva,_ = ml.transforms.rescale(Xva,param)\n",
    "Xte,_ = ml.transforms.rescale(Xte,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 2 : Jsur = 0.5000477812449063, J01 = 0.4996631862579993\n",
      "it 4 : Jsur = 0.4999928090766285, J01 = 0.4976423038059953\n",
      "it 8 : Jsur = 0.49988780520223935, J01 = 0.4991579656449983\n",
      "it 16 : Jsur = 0.5031685175572981, J01 = 0.5271135062310542\n",
      "it 32 : Jsur = 0.5140711395803385, J01 = 0.4922532839339845\n",
      "it 64 : Jsur = 0.49916522516284195, J01 = 0.4592455372179185\n",
      "it 128 : Jsur = 0.5105091991986699, J01 = 0.4363422027618727\n",
      "it 256 : Jsur = 0.5033213610760383, J01 = 0.42842707982485684\n",
      "it 512 : Jsur = 0.48336859936979576, J01 = 0.42135399124284273\n",
      "it 1024 : Jsur = 0.48599222122828123, J01 = 0.42286965308184576\n",
      "it 2048 : Jsur = 0.47091953643147316, J01 = 0.4058605591108117\n",
      "it 4096 : Jsur = 0.4658735373762376, J01 = 0.39003031323678006\n",
      "it 8192 : Jsur = 0.4629875641574865, J01 = 0.3912091613337824\n",
      "it 16384 : Jsur = 0.4618214069471904, J01 = 0.386998989558774\n",
      "it 32768 : Jsur = 0.4613000747530077, J01 = 0.3878410239137757\n",
      "it 65536 : Jsur = 0.46110231858436945, J01 = 0.38683058268777365\n",
      "it 131072 : Jsur = 0.4610042045973542, J01 = 0.386493768945773\n",
      "0.673681917211329\n"
     ]
    }
   ],
   "source": [
    "# simple neural net\n",
    "nHidden = 1000\n",
    "nnet = ml.nnet.nnetClassify()\n",
    "nnet.init_weights([Xtr.shape[1],nHidden,2],'random',Xtr,Ytr);\n",
    "nnet.train(Xtr[:10000,:],Ytr[:10000],stopTol=-1,initStep=0.65,stopIter=150000)\n",
    "\n",
    "print('Validation AUC: '+ str(nnet.auc(Xva, Yva)))\n",
    "\n",
    "nn_ytr_hat = nnet.predictSoft(Xtr)\n",
    "nn_yva_hat = nnet.predictSoft(Xva)\n",
    "nn_yte_hat = nnet.predictSoft(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.6731608569353668\n",
      "Validation Error:  0.22934751895865996\n"
     ]
    }
   ],
   "source": [
    "# boosted linear regressors\n",
    "nUse= 800\n",
    "mu = Ytr.mean()\n",
    "step = 0.1\n",
    "Ft = np.zeros((Xtr.shape[0],)) + np.log(mu/(1-mu))\n",
    "Fv = np.zeros((Xva.shape[0],)) + np.log(mu/(1-mu))\n",
    "Fte = np.zeros((Xte.shape[0],)) + np.log(mu/(1-mu))\n",
    "\n",
    "def sigma(z): return 1./(1.+np.exp(-z))\n",
    "\n",
    "Pt3 = np.zeros((Xtr.shape[0],2)); Pt3[:,0]=1-mu; Pt3[:,1]=mu;\n",
    "Pv3 = np.zeros((Xva.shape[0],2)); Pv3[:,0]=1-mu; Pv3[:,1]=mu;\n",
    "Pte3 = np.zeros((Xte.shape[0],2)); Pte3[:,0]=1-mu; Pte3[:,1]=mu;\n",
    "\n",
    "np.random.seed(0)\n",
    "for l in range(nUse): # this is a lot faster than the bagging loop:\n",
    "    dJ = 1.*Ytr - sigma(Ft)\n",
    "    #tree = ml.dtree.treeRegress(Xtr,dJ, maxDepth=4) # train and save predictions\n",
    "    linc = ml.linear.linearRegress(Xtr,dJ,5.2)\n",
    "    \n",
    "    Ft += step*np.reshape(linc.predict(Xtr), (linc.predict(Xtr).shape[0],))\n",
    "    Fv += step*np.reshape(linc.predict(Xva), (linc.predict(Xva).shape[0],))\n",
    "    Fte += step*np.reshape(linc.predict(Xte), (linc.predict(Xte).shape[0],))\n",
    "    \n",
    "    Pt3[:,1] = sigma(Ft); Pt3[:,0] = 1-Pt3[:,1]\n",
    "    Pv3[:,1] = sigma(Fv); Pv3[:,0] = 1-Pv3[:,1]\n",
    "    Pte3[:,1] = sigma(Fte); Pte3[:,0] = 1-Pte3[:,1]\n",
    "    \n",
    "lin_ytr_hat = Pt3\n",
    "lin_yva_hat = Pv3\n",
    "lin_yte_hat = Pte3\n",
    "    \n",
    "print('Validation AUC: ' + str(dummy(Xva,Yva,lin_yva_hat).auc(Xva,Yva)))    \n",
    "print('Validation Error: ', np.mean((Yva - lin_yva_hat[:,1])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boosted\n",
    "nUse=128\n",
    "mu = Ytr.mean()\n",
    "step = 0.1\n",
    "Ft = np.zeros((Xtr.shape[0],)) + np.log(mu/(1-mu))\n",
    "Fv = np.zeros((Xva.shape[0],)) + np.log(mu/(1-mu))\n",
    "Fte = np.zeros((Xte.shape[0],)) + np.log(mu/(1-mu))\n",
    "\n",
    "def sigma(z): return 1./(1.+np.exp(-z))\n",
    "\n",
    "Pt2 = np.zeros((Xtr.shape[0],2)); Pt2[:,0]=1-mu; Pt2[:,1]=mu;\n",
    "Pv2 = np.zeros((Xva.shape[0],2)); Pv2[:,0]=1-mu; Pv2[:,1]=mu;\n",
    "Pte2 = np.zeros((Xte.shape[0],2)); Pte2[:,0]=1-mu; Pte2[:,1]=mu;\n",
    "\n",
    "np.random.seed(0)\n",
    "for l in range(nUse): # this is a lot faster than the bagging loop:\n",
    "    dJ = 1.*Ytr - sigma(Ft)\n",
    "    tree = ml.dtree.treeRegress(Xtr,dJ, maxDepth=3) # train and save predictions\n",
    "    Ft += step*tree.predict(Xtr)\n",
    "    Fv += step*tree.predict(Xva)\n",
    "    Fte += step*tree.predict(Xte)\n",
    "    \n",
    "    Pt2[:,1] = sigma(Ft); Pt2[:,0] = 1-Pt2[:,1]\n",
    "    Pv2[:,1] = sigma(Fv); Pv2[:,0] = 1-Pv2[:,1]\n",
    "    Pte2[:,1] = sigma(Fte); Pte2[:,0] = 1-Pte2[:,1]\n",
    "    \n",
    "grad_tree_ytr_hat = Pt2\n",
    "grad_tree_yva_hat = Pv2\n",
    "grad_tree_yte_hat = Pte2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.7511283587509077\n",
      "Validation Error: 0.20306751059209563\n"
     ]
    }
   ],
   "source": [
    "print('Validation AUC: ' + str(dummy(Xva,Yva,grad_tree_yva_hat).auc(Xva,Yva)))\n",
    "print('Validation Error: ' + str(np.mean((Yva - grad_tree_yva_hat[:,1])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bagged forest\n",
    "ensemble = []\n",
    "forest_yva_hat = np.ones((Xva.shape[0], 2))\n",
    "forest_ytr_hat = np.ones((Xtr.shape[0], 2))\n",
    "forest_yte_hat = np.ones((Xte.shape[0], 2))\n",
    "\n",
    "nUse = 128\n",
    "for i in range(nUse):\n",
    "    x_boot, y_boot = ml.bootstrapData(Xtr, Ytr, n_boot = Xtr.shape[0])\n",
    "    ensemble.append(ml.dtree.treeClassify(x_boot, y_boot, minParent=64, maxDepth=10, minLeaf=4, nFeatures=13))\n",
    "    \n",
    "    forest_yva_hat += ensemble[i].predictSoft(Xva)\n",
    "    forest_ytr_hat += ensemble[i].predictSoft(Xtr)\n",
    "    forest_yte_hat += ensemble[i].predictSoft(Xte)\n",
    "    \n",
    "forest_yva_hat /= nUse\n",
    "forest_ytr_hat /= nUse\n",
    "forest_yte_hat /= nUse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.7512835875090778\n",
      "Validation Error: 0.20001326778038503\n"
     ]
    }
   ],
   "source": [
    "print('Validation AUC: ' + str(dummy(Xva,Yva,forest_yva_hat).auc(Xva,Yva)))\n",
    "print('Validation Error: ' + str(np.mean((Yva - forest_yva_hat[:,1])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked AUC: 0.7537182280319535\n"
     ]
    }
   ],
   "source": [
    "Sva = np.hstack((nn_yva_hat, lin_yva_hat, grad_tree_yva_hat, forest_yva_hat))\n",
    "stack = ml.linearC.linearClassify(Sva, Yva, reg=1e-20)\n",
    "print('Stacked AUC: ' + str(stack.auc(Sva,Yva)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Training Error: 0.17178736435999392\n",
      "Stacked Validation Error: 0.1978226756149664\n"
     ]
    }
   ],
   "source": [
    "Str = np.hstack((nn_ytr_hat, lin_ytr_hat, grad_tree_ytr_hat, forest_ytr_hat))\n",
    "ytr_hat = stack.predictSoft(Str)\n",
    "yva_hat = stack.predictSoft(Sva)\n",
    "\n",
    "print('Stacked Training Error: ' + str(np.mean((Ytr - ytr_hat[:,1])**2)))\n",
    "print('Stacked Validation Error: ' + str(np.mean((Yva - yva_hat[:,1])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ste = np.hstack((nn_yte_hat, lin_yte_hat, grad_tree_yte_hat, forest_yte_hat))\n",
    "final_ste_hat = stack.predictSoft(Ste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.055103571752166354\n",
      "0.9699543706225553\n"
     ]
    }
   ],
   "source": [
    "print(final_ste_hat[:,1].min())\n",
    "print(final_ste_hat[:,1].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i, r in enumerate(final_ste_hat[:,1]):\n",
    "    result.append([i,r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final = np.vstack((np.arange(final_y_hat.shape[0]), final_y_hat[:,1])).T\n",
    "np.savetxt('projectresults.txt', result,'%d, %.2f',header='Id,Predicted',comments='', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
